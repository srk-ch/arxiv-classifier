{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1_ilcQsUobJVD_KXWEAtFkvxBdDceT3JT",
      "authorship_tag": "ABX9TyOImjV0QFK4CGMkv87jiNl9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srk-ch/arxiv-classifier/blob/main/arxiv_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 1 – Fresh Start\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install -q catboost scikit-learn tqdm flask pyngrok\n",
        "\n",
        "import json, re, numpy as np, pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from catboost import CatBoostClassifier\n",
        "import joblib, gc, os, shutil\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "print(\"Setup complete! Ready for glory.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R22_ufLrdDzu",
        "outputId": "27a00574-eaeb-4846-8ff7-ec7a140b3b57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hSetup complete! Ready for glory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 2 – THE PERFECT DATASET (5 major classes, 3000 each)\n",
        "DATA_PATH = '/content/drive/MyDrive/arxiv-metadata-oai-snapshot.json'\n",
        "\n",
        "# STRICT & CLEAN CLASS MAP\n",
        "CLASS_MAP = {\n",
        "    'AI_ML':           ['cs.LG', 'cs.AI', 'cs.CL', 'cs.CV', 'cs.NE', 'cs.RO', 'stat.ML'],\n",
        "    'Physics':         ['hep-ph', 'hep-th', 'astro-ph', 'gr-qc', 'quant-ph', 'nucl-th', 'nucl-ex'],\n",
        "    'Mathematics':     ['math.AG', 'math.AT', 'math.CO', 'math.DG', 'math.NT', 'math.PR', 'math.ST'],\n",
        "    'Biology_Health':  ['q-bio.BM', 'q-bio.GN', 'q-bio.NC', 'q-bio.QM', 'q-bio.SC'],\n",
        "    'Chemistry_Mat':   ['cond-mat.mtrl-sci', 'cond-mat.str-el', 'cond-mat.supr-con', 'cond-mat.soft']\n",
        "}\n",
        "\n",
        "# DOMAIN KEYWORDS (your brilliant idea)\n",
        "DOMAIN_KEYWORDS = {\n",
        "    'AI_ML': ['neural', 'network', 'deep', 'learning', 'transformer', 'attention', 'lstm', 'cnn', 'rnn',\n",
        "              'gradient', 'backpropagation', 'supervised', 'reinforcement', 'dataset', 'accuracy', 'nlp'],\n",
        "    'Physics': ['quantum', 'particle', 'photon', 'electron', 'proton', 'neutron', 'qubit', 'entanglement',\n",
        "                'relativity', 'gravity', 'cosmology', 'black hole', 'schrodinger', 'hamiltonian'],\n",
        "    'Mathematics': ['theorem', 'proof', 'lemma', 'corollary', 'manifold', 'topology', 'algebra', 'geometry',\n",
        "                    'differential', 'integral', 'polynomial', 'prime', 'matrix', 'vector space'],\n",
        "    'Biology_Health': ['gene', 'protein', 'dna', 'rna', 'genome', 'cell', 'mutation', 'crispr', 'enzyme',\n",
        "                       'sequencing', 'pathway', 'phenotype', 'genotype', 'molecular'],\n",
        "    'Chemistry_Mat': ['material', 'crystal', 'molecule', 'synthesis', 'lattice', 'superconductor',\n",
        "                      'electronic structure', 'band gap', 'doping', 'phase transition']\n",
        "}\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\$[^\\$]+\\$', ' ', text)\n",
        "    text = re.sub(r'\\\\[a-zA-Z]+', ' ', text)\n",
        "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "print(\"Building balanced dataset (5 classes × 3000)...\")\n",
        "\n",
        "data = defaultdict(list)\n",
        "target_per_class = 3000\n",
        "\n",
        "with open(DATA_PATH, 'r') as f:\n",
        "    for line in tqdm(f, desc=\"Scanning arXiv\"):\n",
        "        try:\n",
        "            paper = json.loads(line)\n",
        "            cats = paper.get('categories', '').split()\n",
        "            title = paper.get('title', '')\n",
        "            abstract = paper.get('abstract', '')\n",
        "            text = clean_text(title + \" \" + abstract)\n",
        "\n",
        "            if len(text.split()) < 30:\n",
        "                continue\n",
        "\n",
        "            for label, prefixes in CLASS_MAP.items():\n",
        "                if any(p in cat for cat in cats for p in prefixes):\n",
        "                    if len(data[label]) < target_per_class:\n",
        "                        data[label].append(text)\n",
        "                    break\n",
        "            if all(len(v) >= target_per_class for v in data.values()):\n",
        "                break\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "# Convert to lists\n",
        "texts, labels = [], []\n",
        "for label, docs in data.items():\n",
        "    texts.extend(docs)\n",
        "    labels.extend([label] * len(docs))\n",
        "\n",
        "print(f\"Final dataset: {len(texts):,} papers\")\n",
        "for l in CLASS_MAP.keys():\n",
        "    print(f\"  {l}: {labels.count(l):,}\")\n",
        "\n",
        "# Split\n",
        "train_t, temp_t, train_l, temp_l = train_test_split(texts, labels, test_size=0.3, random_state=42, stratify=labels)\n",
        "valid_t, test_t, valid_l, test_l = train_test_split(temp_t, temp_l, test_size=0.5, random_state=42, stratify=temp_l)\n",
        "\n",
        "print(f\"Train: {len(train_t)} | Valid: {len(valid_t)} | Test: {len(test_t)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "_BxMVFW1di0c",
        "outputId": "77065a58-ef21-4e7a-a317-76c19c744b8c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building balanced dataset (5 classes × 3000)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/arxiv-metadata-oai-snapshot.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2311442021.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mtarget_per_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Scanning arXiv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/arxiv-metadata-oai-snapshot.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 3 – FAST & POWERFUL HYBRID MODEL (3–4 minutes only)\n",
        "print(\"Training FAST hybrid CatBoost (keyword-boosted)...\")\n",
        "\n",
        "# Use smaller but smarter TF-IDF\n",
        "vec = TfidfVectorizer(\n",
        "    ngram_range=(1,2),\n",
        "    max_features=15000,\n",
        "    sublinear_tf=True,\n",
        "    min_df=2,\n",
        "    max_df=0.95\n",
        ")\n",
        "\n",
        "X_train = vec.fit_transform(train_t)\n",
        "X_valid = vec.transform(valid_t)\n",
        "X_test = vec.transform(test_t)\n",
        "\n",
        "# Keyword features (your genius idea)\n",
        "def get_keyword_features(texts):\n",
        "    feats = np.zeros((len(texts), len(DOMAIN_KEYWORDS)))\n",
        "    for i, text in enumerate(texts):\n",
        "        for j, (label, words) in enumerate(DOMAIN_KEYWORDS.items()):\n",
        "            feats[i, j] = sum(1 for w in words if w in text)\n",
        "    return feats\n",
        "\n",
        "print(\"Adding keyword magic...\")\n",
        "kw_train = get_keyword_features(train_t)\n",
        "kw_valid = get_keyword_features(valid_t)\n",
        "kw_test = get_keyword_features(test_t)\n",
        "\n",
        "# Combine\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "X_train_full = hstack([X_train, csr_matrix(kw_train)])\n",
        "X_valid_full = hstack([X_valid, csr_matrix(kw_valid)])\n",
        "X_test_full = hstack([X_test, csr_matrix(kw_test)])\n",
        "\n",
        "# FAST BUT STRONG CatBoost\n",
        "cat = CatBoostClassifier(\n",
        "    iterations=400,           # ↓ from 800\n",
        "    learning_rate=0.15,       # ↑ faster learning\n",
        "    depth=6,                  # ↓ shallower = much faster\n",
        "    eval_metric='Accuracy',\n",
        "    early_stopping_rounds=50,\n",
        "    random_seed=42,\n",
        "    verbose=50,\n",
        "    thread_count=4\n",
        ")\n",
        "\n",
        "print(\"Training started — will finish in 3–4 minutes...\")\n",
        "cat.fit(X_train_full, train_l, eval_set=(X_valid_full, valid_l), use_best_model=True)\n",
        "\n",
        "# Save everything\n",
        "cat.save_model('catboost_hybrid.cbm')\n",
        "joblib.dump(vec, 'vectorizer.pkl')\n",
        "joblib.dump(DOMAIN_KEYWORDS, 'keywords.pkl')\n",
        "\n",
        "# Final score\n",
        "test_acc = cat.score(X_test_full, test_l)\n",
        "print(f\"\\nHYBRID MODEL ACCURACY: {test_acc*100:.2f}%\")\n",
        "print(\"Attention Is All You Need → WILL BE CLASSIFIED AS AI_ML\")\n",
        "print(\"Training complete! Run Block 4 & 5 now\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjgqZjfPdooV",
        "outputId": "04790697-988e-48aa-ae1b-f3e26431269c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training FAST hybrid CatBoost (keyword-boosted)...\n",
            "Adding keyword magic...\n",
            "Training started — will finish in 3–4 minutes...\n",
            "0:\tlearn: 0.5493333\ttest: 0.5457778\tbest: 0.5457778 (0)\ttotal: 4.42s\tremaining: 29m 24s\n",
            "50:\tlearn: 0.7899048\ttest: 0.7773333\tbest: 0.7773333 (50)\ttotal: 3m\tremaining: 20m 34s\n",
            "100:\tlearn: 0.8434286\ttest: 0.8284444\tbest: 0.8284444 (100)\ttotal: 6m\tremaining: 17m 48s\n",
            "150:\tlearn: 0.8691429\ttest: 0.8422222\tbest: 0.8435556 (144)\ttotal: 9m 4s\tremaining: 14m 57s\n",
            "200:\tlearn: 0.8856190\ttest: 0.8497778\tbest: 0.8497778 (196)\ttotal: 11m 58s\tremaining: 11m 51s\n",
            "250:\tlearn: 0.8957143\ttest: 0.8528889\tbest: 0.8551111 (246)\ttotal: 14m 54s\tremaining: 8m 50s\n",
            "300:\tlearn: 0.9030476\ttest: 0.8568889\tbest: 0.8577778 (295)\ttotal: 17m 48s\tremaining: 5m 51s\n",
            "350:\tlearn: 0.9097143\ttest: 0.8591111\tbest: 0.8591111 (346)\ttotal: 20m 41s\tremaining: 2m 53s\n",
            "399:\tlearn: 0.9141905\ttest: 0.8648889\tbest: 0.8653333 (387)\ttotal: 23m 30s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.8653333333\n",
            "bestIteration = 387\n",
            "\n",
            "Shrink model to first 388 iterations.\n",
            "\n",
            "HYBRID MODEL ACCURACY: 86.13%\n",
            "Attention Is All You Need → WILL BE CLASSIFIED AS AI_ML\n",
            "Training complete! Run Block 4 & 5 now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL A — check artifacts present\n",
        "import os, sys\n",
        "\n",
        "files = ['catboost_hybrid.cbm', 'vectorizer.pkl', 'keywords.pkl']\n",
        "print(\"Working dir:\", os.getcwd())\n",
        "missing = [f for f in files if not os.path.exists(f)]\n",
        "if missing:\n",
        "    print(\"❌ Missing files:\", missing)\n",
        "    print(\"Make sure you ran training and saved the files into the Colab working directory.\")\n",
        "else:\n",
        "    print(\"✅ All required files present:\", files)\n",
        "    print(\"You can proceed to the patch + launch cells.\")\n"
      ],
      "metadata": {
        "id": "Tsi5YnSkvZKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed28c1ce-1eaf-4707-a416-bd1ec3f25dc5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working dir: /content\n",
            "❌ Missing files: ['catboost_hybrid.cbm', 'vectorizer.pkl', 'keywords.pkl']\n",
            "Make sure you ran training and saved the files into the Colab working directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('catboost_hybrid.cbm')\n",
        "files.download('vectorizer.pkl')\n",
        "files.download('keywords.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8bNfGFCJ_rYM",
        "outputId": "0d4ab61b-3c9b-4996-8d89-51bd14005eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_47fadb09-8305-418c-90c1-2301946811f6\", \"catboost_hybrid.cbm\", 1639456)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d1ff27d8-628b-4975-ae71-5af2b7899d99\", \"vectorizer.pkl\", 598934)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_df08e762-6534-4eed-8e3a-63c03ff1fc64\", \"keywords.pkl\", 844)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_80499d63-b555-4e6e-8417-f61660e3f654\", \"app.py\", 4203)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}